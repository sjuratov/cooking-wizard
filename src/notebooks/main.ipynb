{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "sys.path.append(\"..\")\n",
    "from utils import load_azd_env, set_azure_ai_project_connection_string, setup_logging, get_file_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_azd_env()\n",
    "set_azure_ai_project_connection_string()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "enbale_logging = False\n",
    "\n",
    "if enbale_logging:\n",
    "    setup_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test if FastAPI server is operational"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'echo_msg': 'Echo: Hello, World!'}\n"
     ]
    }
   ],
   "source": [
    "project = requests.post(\n",
    "    url = \"http://127.0.0.1:8000/echo\",\n",
    "    json = {\n",
    "        \"msg\": \"Hello, World!\"\n",
    "    }\n",
    "    )\n",
    "print(project.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Azure AI Foundry project client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.projects import AIProjectClient\n",
    "\n",
    "logging.info('create_project_client trigger function started processing a request.')\n",
    "\n",
    "project_connection_string = os.getenv(\"AZURE_AI_FOUNDRY_CONNECTION_STRING\")\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "\n",
    "project_client = AIProjectClient.from_connection_string(\n",
    "    conn_str=project_connection_string,\n",
    "    credential=credential\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create OpenAI client and call chat completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In meadows where the sunlight spills,\n",
      "Where breezes hum and nature thrills,\n",
      "The flowers bloom in colors bright,\n",
      "A tapestry of pure delight.\n",
      "\n",
      "The daisies nod with faces fair,\n",
      "As if to greet the morning air,\n",
      "While roses blush with crimson hue,\n",
      "Their petals kissed by morning dew.\n",
      "\n",
      "Bluebells chime in quiet glades,\n",
      "Their delicate, cerulean shades,\n",
      "And tulips stand in proud array,\n",
      "Like soldiers on a springtime day.\n",
      "\n",
      "The lavender, with fragrance sweet,\n",
      "Beguiles the senses, oh so fleet,\n",
      "While sunflowers with golden crowns,\n",
      "Reflect the joy that summer found.\n",
      "\n",
      "Hyacinths in clusters bloom,\n",
      "Filling hearts with sweet perfume,\n",
      "In colors rich and subtle too,\n",
      "A spectrum dancing 'neath the blue.\n",
      "\n",
      "And orchids, rarest of the rare,\n",
      "With elegance beyond compare,\n",
      "Unfold their secrets to the sky,\n",
      "A mystery for every eye.\n",
      "\n",
      "So many blooms, each one unique,\n",
      "A language only they can speak,\n",
      "In gardens wild or tended close,\n",
      "They share a beauty we repose.\n",
      "\n",
      "In petals soft, in colors riot,\n",
      "In stillness deep or buzzing quiet,\n",
      "The flowers tell of lifeâ€™s embrace,\n",
      "Our world adorned with nature's grace.\n"
     ]
    }
   ],
   "source": [
    "openai = project_client.inference.get_azure_openai_client(api_version=\"2024-06-01\")\n",
    "response = openai.chat.completions.create(\n",
    "    model=os.environ[\"AZURE_AI_DEPLOYMENT_MODEL\"],\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful writing assistant\"},\n",
    "        {\"role\": \"user\", \"content\": \"Write me a poem about flowers\"},\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created vector store, vector store ID: vs_9CCmnIrSEAfFoKqLZ2JuYRNW\n",
      "Uploaded file, file ID: assistant-MRMCfHqlatBnZEh1qEzbUdjn\n",
      "Uploaded file, file ID: assistant-ZYsGHZSewXYAGNdzVdXAKubh\n",
      "Uploaded file, file ID: assistant-dvCdeDk8Zyscq8BfzPIjcoqk\n",
      "Created vector store file batch, vector store file batch ID: vsfb_139a05cc60514ca6a0e0777899cbc02e\n",
      "Created agent, agent ID: asst_1roJsYXx7HQRVb0Jg67lCGhE\n",
      "Created thread, thread ID: thread_qhqHxxDZeZs95aOER4XbCdQM\n",
      "Created message, message ID: msg_XhVpMPdRiRwqvmIaTTfZ6gGn\n",
      "Created run, run ID: run_NvqiQGUZL74NgbjhFc668Oeq\n",
      "Removed vector store from file search, vector store ID: vs_9CCmnIrSEAfFoKqLZ2JuYRNW\n",
      "Updated agent, agent ID: asst_1roJsYXx7HQRVb0Jg67lCGhE\n",
      "Created thread, thread ID: thread_p6P6wakLrCUUbQx2slGstQu8\n",
      "Created message, message ID: msg_My6NNO0P5MZBjUBzJgxwCbht\n",
      "Created run, run ID: run_wqp6EciASa5DZVUFmFgFLASC\n",
      "Deleted vector store\n",
      "Deleted agent\n",
      "Messages: {'object': 'list', 'data': [{'id': 'msg_My6NNO0P5MZBjUBzJgxwCbht', 'object': 'thread.message', 'created_at': 1735236197, 'assistant_id': None, 'thread_id': 'thread_p6P6wakLrCUUbQx2slGstQu8', 'run_id': None, 'role': 'user', 'content': [{'type': 'text', 'text': {'value': 'How long does it take to prepare Christmas Pudding?', 'annotations': []}}], 'attachments': [], 'metadata': {}}], 'first_id': 'msg_My6NNO0P5MZBjUBzJgxwCbht', 'last_id': 'msg_My6NNO0P5MZBjUBzJgxwCbht', 'has_more': False}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DESCRIPTION:\n",
    "    This sample demonstrates how to use agent operations to add files to an existing vector store and perform search from\n",
    "    the Azure Agents service using a synchronous client.\n",
    "\n",
    "USAGE:\n",
    "    python sample_agents_vector_store_batch_file_search.py\n",
    "\n",
    "    Before running the sample:\n",
    "\n",
    "    pip install azure-ai-projects azure-identity\n",
    "\n",
    "    Set this environment variables with your own values:\n",
    "    PROJECT_CONNECTION_STRING - the Azure AI Project connection string, as found in your AI Foundry project.\n",
    "\"\"\"\n",
    "\n",
    "from azure.ai.projects.models import FileSearchTool, FilePurpose\n",
    "\n",
    "files = get_file_paths(data_folder = \"../../data\")\n",
    "\n",
    "with project_client:\n",
    "\n",
    "    # Create a vector store with no file and wait for it to be processed\n",
    "    vector_store = project_client.agents.create_vector_store_and_poll(data_sources=[], name=\"sample_vector_store\")\n",
    "    print(f\"Created vector store, vector store ID: {vector_store.id}\")\n",
    "\n",
    "    # Upload a file and wait for it to be processed\n",
    "    file_ids = []\n",
    "    for file in files:\n",
    "        file = project_client.agents.upload_file_and_poll(file_path=file, purpose=FilePurpose.AGENTS)\n",
    "        print(f\"Uploaded file, file ID: {file.id}\")\n",
    "        file_ids.append(file.id)\n",
    "\n",
    "    # Add the file to the vector store or you can supply file ids in the vector store creation\n",
    "    vector_store_file_batch = project_client.agents.create_vector_store_file_batch_and_poll(\n",
    "        vector_store_id=vector_store.id, file_ids=file_ids\n",
    "    )\n",
    "    print(f\"Created vector store file batch, vector store file batch ID: {vector_store_file_batch.id}\")\n",
    "\n",
    "    # Create a file search tool\n",
    "    # [START create_agent_with_tools_and_tool_resources]\n",
    "    file_search_tool = FileSearchTool(vector_store_ids=[vector_store.id])\n",
    "\n",
    "    # Notices that FileSearchTool as tool and tool_resources must be added or the assistant unable to search the file\n",
    "    agent = project_client.agents.create_agent(\n",
    "        model=os.environ[\"AZURE_AI_DEPLOYMENT_MODEL\"],\n",
    "        name=\"my-assistant\",\n",
    "        instructions=\"You are helpful assistant and can search information from uploaded files\",\n",
    "        tools=file_search_tool.definitions,\n",
    "        tool_resources=file_search_tool.resources,\n",
    "    )\n",
    "    # [END create_agent_with_tools_and_tool_resources]\n",
    "    print(f\"Created agent, agent ID: {agent.id}\")\n",
    "\n",
    "    thread = project_client.agents.create_thread()\n",
    "    print(f\"Created thread, thread ID: {thread.id}\")\n",
    "\n",
    "    message = project_client.agents.create_message(\n",
    "        thread_id=thread.id, role=\"user\", content=\"How long does it take to prepare Christmas Pudding?\"\n",
    "    )\n",
    "    print(f\"Created message, message ID: {message.id}\")\n",
    "\n",
    "    run = project_client.agents.create_and_process_run(thread_id=thread.id, assistant_id=agent.id)\n",
    "    print(f\"Created run, run ID: {run.id}\")\n",
    "\n",
    "    file_search_tool.remove_vector_store(vector_store.id)\n",
    "    print(f\"Removed vector store from file search, vector store ID: {vector_store.id}\")\n",
    "\n",
    "    project_client.agents.update_agent(\n",
    "        assistant_id=agent.id, tools=file_search_tool.definitions, tool_resources=file_search_tool.resources\n",
    "    )\n",
    "    print(f\"Updated agent, agent ID: {agent.id}\")\n",
    "\n",
    "    thread = project_client.agents.create_thread()\n",
    "    print(f\"Created thread, thread ID: {thread.id}\")\n",
    "\n",
    "    message = project_client.agents.create_message(\n",
    "        thread_id=thread.id, role=\"user\", content=\"How long does it take to prepare Christmas Pudding?\"\n",
    "    )\n",
    "    print(f\"Created message, message ID: {message.id}\")\n",
    "\n",
    "    run = project_client.agents.create_and_process_run(thread_id=thread.id, assistant_id=agent.id)\n",
    "    print(f\"Created run, run ID: {run.id}\")\n",
    "\n",
    "    project_client.agents.delete_vector_store(vector_store.id)\n",
    "    print(\"Deleted vector store\")\n",
    "\n",
    "    project_client.agents.delete_agent(agent.id)\n",
    "    print(\"Deleted agent\")\n",
    "\n",
    "    messages = project_client.agents.list_messages(thread_id=thread.id)\n",
    "    print(f\"Messages: {messages}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
